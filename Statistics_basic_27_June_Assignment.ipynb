{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Assignment Statistis basics"
      ],
      "metadata": {
        "id": "AWPXh-BNZnMH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Theory Questions"
      ],
      "metadata": {
        "id": "4_P27GSiZvo2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 = What is statistics, and why is it important ?\n",
        "\n",
        "Ans = Statistics is a branch of mathematics that deals with the collection, organization, analysis, interpretation, and presentation of numerical data. It is a systematic method used to understand and describe variability in data and to make informed decisions based on that information. The word statistics comes from the Latin word status, meaning state, indicating its historical use in gathering data about states and governments.\n",
        "\n",
        "Importance of Statistics\n",
        "\n",
        "Statistics plays a vital role in various fields and everyday life due to the following reasons:\n",
        "\n",
        "1. Decision Making: Statistics provides a scientific basis for decision-making. Governments, businesses, and individuals use statistical data to make policies, plan strategies, and forecast future trends.\n",
        "\n",
        "2. Research and Development: In scientific research, statistics is crucial for designing experiments, analyzing experimental results, and validating hypotheses. It helps in drawing accurate and reliable conclusions.\n",
        "\n",
        "3. Understanding and Controlling Variability: Natural and social phenomena often involve variability. Statistics helps in understanding patterns, causes of variation, and controlling processes in areas such as manufacturing and quality control.\n",
        "\n",
        "4. Economic Planning: Economists and policymakers use statistics to analyze economic problems, study market trends, calculate national income, and formulate economic policies.\n",
        "\n",
        "5. Social Sciences: In sociology, psychology, and education, statistical methods are used to study human behavior, social issues, and educational outcomes.\n",
        "\n",
        "6. Business and Industry: Businesses use statistics for market research, product development, customer satisfaction analysis, and risk management.\n",
        "\n",
        "7. Daily Life Applications: Individuals use statistics in everyday life for tasks like budgeting, analyzing health data, comparing products, and understanding news reports that involve data and percentages."
      ],
      "metadata": {
        "id": "Sh1UGUbtZ0Ne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 = What are the two main types of statistics ?\n",
        "\n",
        "Ans = Two Main Types of Statistics:\n",
        "\n",
        "Statistics, as a field of study, is broadly classified into two main types: Descriptive Statistics and Inferential Statistics. Each type serves a distinct purpose and plays a crucial role in data analysis and interpretation.\n",
        "\n",
        "1. Descriptive Statistics\n",
        "Descriptive statistics refers to the methods used to summarize, organize, and present data in an informative way. It provides simple quantitative descriptions of the features of a dataset, allowing us to understand and interpret the main characteristics of the data without drawing conclusions beyond it.\n",
        "\n",
        "2. Inferential statistics involves techniques that allow us to make predictions, inferences, or generalizations about a larger population based on a sample of data taken from it. It goes beyond describing data to making conclusions and testing hypotheses about relationships and differences among variables."
      ],
      "metadata": {
        "id": "8CjV1MLJcP1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 =  What are descriptive statistics ?\n",
        "\n",
        "Ans = Descriptive statistics is a branch of statistics that deals with the collection, summarization, organization, and presentation of data in a meaningful and understandable form. It provides simple numerical and graphical tools to describe and highlight the main features of a dataset without making any conclusions or inferences about a larger population.\n",
        "\n",
        "The primary purpose of descriptive statistics is to simplify large amounts of data into a few summary measures and visual representations, making it easier to interpret and communicate the information effectively.\n",
        "\n",
        "Descriptive statistics is important because:\n",
        "\n",
        "It simplifies complex data sets, making them easier to understand.\n",
        "\n",
        "It helps identify patterns, trends, and outliers in data.\n",
        "\n",
        "It provides a foundation for further statistical analysis, including inferential statistics.\n",
        "\n",
        "It aids in effective communication of data insights through charts and tables."
      ],
      "metadata": {
        "id": "_a_2_iVCcxeL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 = What is inferential statistics ?\n",
        "\n",
        "Ans = Inferential statistics is a branch of statistics that focuses on making predictions, inferences, and generalizations about a larger population based on information obtained from a smaller sample of data. Unlike descriptive statistics, which only summarizes and describes the features of a dataset, inferential statistics allows us to draw conclusions and make decisions beyond the data at hand.\n",
        "\n",
        "The primary aim of inferential statistics is to analyze sample data to estimate population parameters, test hypotheses, and determine relationships between variables, all while accounting for the uncertainty that comes from using a sample instead of the whole population.\n",
        "\n",
        "Importance of Inferential Statistics\n",
        "\n",
        "Inferential statistics is essential for:\n",
        "\n",
        "Making decisions when it is impractical or impossible to study an entire population.\n",
        "\n",
        "Drawing valid conclusions and generalizations from limited data.\n",
        "\n",
        "Assessing the reliability and uncertainty of predictions and decisions.\n",
        "\n",
        "Supporting scientific research, business strategies, public policy, and various fields where data-driven decisions are required.\n",
        "\n"
      ],
      "metadata": {
        "id": "EPf4DnEAc9vT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 What is sampling in statistics ?\n",
        "\n",
        "Ans = Sampling is the process of selecting a small group (called a sample) from a larger group (called a population) to gather information and draw conclusions about the whole population.\n",
        "\n",
        "Since it is often difficult, time-consuming, or expensive to study every member of a population, statisticians use samples to make estimates or test hypotheses about the population.\n",
        "\n",
        "Key points about sampling:\n",
        "\n",
        "A sample should be representative of the population to give accurate results.\n",
        "\n",
        "There are different sampling methods, such as random sampling, systematic sampling, stratified sampling, and cluster sampling.\n",
        "\n",
        "Good sampling reduces bias and improves the reliability and validity of statistical conclusions."
      ],
      "metadata": {
        "id": "NoaxH6mWdMLT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 What are the different types of sampling methods ?\n",
        "\n",
        "Ans = Types of Sampling Methods\n",
        "\n",
        "Sampling methods are broadly divided into two main categories:\n",
        "\n",
        "1️⃣ Probability Sampling\n",
        "2️⃣ Non-Probability Sampling\n",
        "\n",
        "1. Probability Sampling\n",
        "\n",
        "In probability sampling, every member of the population has a known and equal chance of being selected. It is more scientific and less biased. Main types include:\n",
        "\n",
        "a) Simple Random Sampling\n",
        "\n",
        "Every member has an equal chance of being selected.\n",
        "\n",
        "Example: Picking names from a hat.\n",
        "\n",
        "b) Systematic Sampling\n",
        "\n",
        "Select every kth member from a list.\n",
        "\n",
        "Example: Choosing every 10th student from an attendance register.\n",
        "\n",
        "c) Stratified Sampling\n",
        "\n",
        "The population is divided into subgroups (strata) based on a characteristic (e.g., age, gender), and samples are taken from each subgroup.\n",
        "\n",
        "Example: Dividing a class by gender and sampling equal numbers from each.\n",
        "\n",
        "d) Cluster Sampling\n",
        "\n",
        "The population is divided into clusters (usually based on location or groups), then whole clusters are randomly selected.\n",
        "\n",
        "Example: Selecting entire classrooms in a school instead of individual students.\n",
        "\n",
        "2. Non-Probability Sampling\n",
        "\n",
        "In non-probability sampling, not all members have a known or equal chance of being selected. It is quicker and easier but may be biased. Common types are:\n",
        "\n",
        "a) Convenience Sampling\n",
        "\n",
        "Selecting whoever is easiest to reach.\n",
        "\n",
        "Example: Interviewing people walking by on a street.\n",
        "\n",
        "b) Judgement/Purposive Sampling\n",
        "\n",
        "The researcher selects subjects based on their own judgement about who will be most useful.\n",
        "\n",
        "Example: Choosing experts for a panel discussion.\n",
        "\n",
        "c) Quota Sampling\n",
        "\n",
        "Similar to stratified sampling, but selection within each subgroup is non-random.\n",
        "\n",
        "Example: Interviewing 50 men and 50 women, but picking them by convenience.\n",
        "\n",
        "d) Snowball Sampling\n",
        "\n",
        "Existing participants recruit future participants.\n",
        "\n",
        "Useful for hard-to-reach populations.\n",
        "\n",
        "Example: Studying drug users by asking participants to refer others.\n"
      ],
      "metadata": {
        "id": "AL351iOR3Ilv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7 What is the difference between random and non-random sampling ?\n",
        "\n",
        "Ans = Random Sampling:\n",
        "\n",
        "Random sampling is a sampling method in which every member of the population has an equal and known chance of being selected in the sample. It is based purely on the principle of chance and removes personal bias in the selection process. Random sampling helps in obtaining a representative sample, which increases the reliability and accuracy of the results. Common types of random sampling include simple random sampling, systematic sampling, stratified sampling, and cluster sampling.\n",
        "\n",
        "Non-Random Sampling:\n",
        "\n",
        "Non-random sampling, also known as non-probability sampling, is a method in which the samples are selected based on the convenience or judgement of the researcher rather than using random selection. In this method, not every member of the population has a chance of being included in the sample. It is easier, quicker, and less expensive but may lead to biased results because the sample may not accurately represent the whole population. Examples of non-random sampling include convenience sampling, judgement or purposive sampling, quota sampling, and snowball sampling."
      ],
      "metadata": {
        "id": "3gLEHDZ43vuA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8 = Define and give examples of qualitative and quantitative data ?\n",
        "\n",
        "Ans = Qualitative and Quantitative Data\n",
        "\n",
        "Qualitative Data:\n",
        "\n",
        "Definition:\n",
        "\n",
        "Qualitative data refers to non-numerical information that describes qualities or characteristics. It deals with descriptions and can be observed but not measured numerically. It is also known as categorical data.\n",
        "\n",
        "Examples:\n",
        "\n",
        "Colours of cars in a parking lot (red, blue, black).\n",
        "\n",
        "Types of cuisine in a restaurant (Italian, Chinese, Indian).\n",
        "\n",
        "Gender of students in a class (male, female).\n",
        "\n",
        "Customer feedback (satisfied, neutral, dissatisfied).\n",
        "\n",
        "Quantitative Data:\n",
        "\n",
        "Definition:\n",
        "\n",
        "Quantitative data refers to numerical information that can be measured and counted. It deals with quantities and expresses information in numbers. It can be further divided into discrete data (countable) and continuous data (measurable).\n",
        "\n",
        "Examples:\n",
        "\n",
        "Number of students in a classroom (30, 45).\n",
        "\n",
        "Height of a person (160 cm, 175 cm).\n",
        "\n",
        "Marks obtained in an exam (85 out of 100).\n",
        "\n",
        "Temperature of a city (25°C, 30°C).\n",
        "\n"
      ],
      "metadata": {
        "id": "MreEHMXU4BvX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9 = What are the different types of data in statistics ?\n",
        "\n",
        "Ans = Different Types of Data in Statistics\n",
        "\n",
        "In statistics, data can be broadly classified into two main categories:\n",
        "\n",
        "1️⃣ Qualitative Data (also called Categorical Data)\n",
        "\n",
        "2️⃣ Quantitative Data (also called Numerical Data)\n",
        "\n",
        "1. Qualitative Data\n",
        "\n",
        "Definition:\n",
        "\n",
        "Qualitative data represents descriptive attributes, labels, or categories. It describes qualities or characteristics and cannot be measured numerically.\n",
        "\n",
        "Types of Qualitative Data:\n",
        "a) Nominal Data:\n",
        "\n",
        "It consists of categories without any natural order or ranking.\n",
        "\n",
        "Examples: Gender (male, female), Blood group (A, B, AB, O), Types of fruit (apple, banana, mango).\n",
        "\n",
        "b) Ordinal Data:\n",
        "\n",
        "It consists of categories with a meaningful order or ranking, but the intervals between ranks are not equal.\n",
        "\n",
        "Examples: Education level (primary, secondary, higher), Customer satisfaction rating (poor, fair, good, excellent), Socio-economic status (low, middle, high).\n",
        "\n",
        "2. Quantitative Data\n",
        "\n",
        "Definition:\n",
        "\n",
        "Quantitative data represents numerical values that can be measured and counted. It deals with quantities and numerical computations.\n",
        "\n",
        "Types of Quantitative Data:\n",
        "a) Discrete Data:\n",
        "\n",
        "It consists of countable values, usually whole numbers.\n",
        "\n",
        "Examples: Number of students in a class (25, 30), Number of cars in a parking lot (10, 15), Number of books on a shelf.\n",
        "\n",
        "b) Continuous Data:\n",
        "\n",
        "It consists of measurable quantities that can take any value within a given range.\n",
        "\n",
        "Examples: Height of a person (165.5 cm), Weight (60.2 kg), Temperature (37.5°C), Time taken to complete a task.\n",
        "\n"
      ],
      "metadata": {
        "id": "_Tj6VpKp4UBv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10 = Explain nominal, ordinal, interval, and ratio levels of measurement ?\n",
        "\n",
        "Ans = Levels of Measurement\n",
        "In statistics, data can be classified based on the level of measurement. This classification helps determine the type of analysis that can be performed on the data. There are four levels of measurement, arranged from the simplest to the most complex:\n",
        "\n",
        "1. Nominal Level\n",
        "\n",
        "Definition:\n",
        "\n",
        "Nominal level is the simplest level of measurement. It involves data that can be categorized but has no order or ranking. The numbers or labels assigned are just names.\n",
        "\n",
        "Characteristics:\n",
        "\n",
        "Categories are distinct and mutually exclusive.\n",
        "\n",
        "No logical order.\n",
        "\n",
        "Only counting or classification is possible.\n",
        "\n",
        "Examples:\n",
        "\n",
        "Gender (male, female)\n",
        "\n",
        "Blood group (A, B, AB, O)\n",
        "\n",
        "Nationality (Indian, American, Chinese)\n",
        "\n",
        "2. Ordinal Level\n",
        "\n",
        "Definition:\n",
        "\n",
        "Ordinal level involves data that can be categorized and ranked in a meaningful order. However, the differences between the ranks are not measurable or equal.\n",
        "\n",
        "Characteristics:\n",
        "\n",
        "Categories have a natural order.\n",
        "\n",
        "Exact differences between ranks are unknown.\n",
        "\n",
        "Used for rankings or preference levels.\n",
        "\n",
        "Examples:\n",
        "\n",
        "Education level (primary, secondary, higher)\n",
        "\n",
        "Customer satisfaction (unsatisfied, neutral, satisfied)\n",
        "\n",
        "Class rank (1st, 2nd, 3rd)\n",
        "\n",
        "3. Interval Level\n",
        "\n",
        "Definition:\n",
        "\n",
        "Interval level involves data with meaningful order and equal intervals between values, but no true zero point.\n",
        "\n",
        "Characteristics:\n",
        "\n",
        "Differences between values are meaningful and equal.\n",
        "\n",
        "Addition and subtraction are possible.\n",
        "\n",
        "No absolute zero, so ratios are not meaningful.\n",
        "\n",
        "Examples:\n",
        "\n",
        "Temperature in Celsius or Fahrenheit (0°C does not mean ‘no temperature’).\n",
        "\n",
        "Dates in a calendar (difference between years).\n",
        "\n",
        "4. Ratio Level\n",
        "\n",
        "Definition:\n",
        "\n",
        "Ratio level is the highest level of measurement. It has all the properties of interval data plus a true zero point, which allows for meaningful ratios.\n",
        "\n",
        "Characteristics:\n",
        "\n",
        "Has order, equal intervals, and an absolute zero.\n",
        "\n",
        "All arithmetic operations (addition, subtraction, multiplication, division) are valid.\n",
        "\n",
        "Ratios make sense (e.g., twice as much).\n",
        "\n",
        "Examples:\n",
        "\n",
        "Height (170 cm)\n",
        "\n",
        "Weight (60 kg)\n",
        "\n",
        "Age (20 years)\n",
        "\n",
        "Income (₹50,000)\n"
      ],
      "metadata": {
        "id": "TK7YiSbD4paX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11 = What is the measure of central tendency ?\n",
        "\n",
        "Ans = Definition:\n",
        "\n",
        "A measure of central tendency is a statistical value that represents the center point or typical value of a dataset. It indicates where most of the data values cluster in a distribution. In simple words, it is used to find the average or middle value around which the data is distributed.\n",
        "\n",
        "Purpose:\n",
        "\n",
        "The main purpose of measures of central tendency is to provide a single value that summarizes a large set of data and gives an idea about the overall trend of the data.\n",
        "\n",
        "Common Measures of Central Tendency:\n",
        "\n",
        "1️⃣ Mean:\n",
        "\n",
        "Also known as the arithmetic average.\n",
        "\n",
        "It is calculated by adding all the data values and dividing by the number of values.\n",
        "\n",
        "Example: If marks are 60, 70, 80 → Mean = (60+70+80)/3 = 70.\n",
        "\n",
        "2️⃣ Median:\n",
        "\n",
        "It is the middle value of an ordered dataset.\n",
        "\n",
        "If the number of values is odd, the median is the middle value.\n",
        "\n",
        "If the number is even, the median is the average of the two middle values.\n",
        "\n",
        "Example: In 10, 20, 30, the median is 20.\n",
        "\n",
        "3️⃣ Mode:\n",
        "\n",
        "It is the most frequently occurring value in a dataset.\n",
        "\n",
        "A dataset can have no mode, one mode, or multiple modes.\n",
        "\n",
        "Example: In 2, 4, 4, 5 → Mode = 4.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f6R9m8Vg5Cy3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12 = Define mean, median, and mode ?\n",
        "\n",
        "Ans = Mean\n",
        "\n",
        "Definition:\n",
        "\n",
        "The mean is the arithmetic average of a set of values. It is calculated by adding up all the values in the dataset and then dividing the sum by the total number of values.\n",
        "\n",
        "Formula:\n",
        "\n",
        "Mean\n",
        "=\n",
        "Sum of all values\n",
        "Number of values\n",
        "Mean=\n",
        "Number of values\n",
        "Sum of all values\n",
        "​\n",
        "\n",
        "Example:\n",
        "If the marks obtained are 50, 60, and 70, then:\n",
        "Mean = (50 + 60 + 70) / 3 = 180 / 3 = 60\n",
        "\n",
        "2. Median\n",
        "\n",
        "Definition:\n",
        "\n",
        "The median is the middle value of a dataset when the values are arranged in ascending or descending order.\n",
        "\n",
        "If the number of values is odd, the median is the middle value.\n",
        "\n",
        "If the number of values is even, the median is the average of the two middle values.\n",
        "\n",
        "Example:\n",
        "For data: 10, 20, 30\n",
        "Median = 20 (middle value)\n",
        "\n",
        "For data: 10, 20, 30, 40\n",
        "Median = (20 + 30) / 2 = 25\n",
        "\n",
        "3. Mode\n",
        "\n",
        "Definition:\n",
        "\n",
        "The mode is the value that occurs most frequently in a dataset. A dataset can have no mode, one mode, or multiple modes if multiple values occur with the same highest frequency.\n",
        "\n",
        "Example:\n",
        "For data: 2, 3, 3, 5, 7\n",
        "Mode = 3 (occurs twice)\n",
        "\n",
        "For data: 4, 4, 5, 5, 6\n",
        "Modes = 4 and 5 (both occur twice)\n",
        "\n"
      ],
      "metadata": {
        "id": "VYj94woI5iWX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13 = What is the significance of the measure of central tendency ?\n",
        "\n",
        "Ans= Significance of the Measure of Central Tendency\n",
        "\n",
        "Definition:\n",
        "\n",
        "Measures of central tendency, such as mean, median, and mode, are important statistical tools that provide a single value representing the entire dataset. They indicate where most data points are centered or clustered.\n",
        "\n",
        "Significance:\n",
        "\n",
        "1️⃣ Simplifies Complex Data:\n",
        "Measures of central tendency reduce a large set of data to a single representative value, making it easier to understand and interpret.\n",
        "\n",
        "2️⃣ Helps in Comparison:\n",
        "They allow comparison between different datasets or groups by providing a common basis for evaluation. For example, comparing average marks of two classes.\n",
        "\n",
        "3️⃣ Useful in Decision Making:\n",
        "They help managers, researchers, and policymakers make informed decisions based on typical values, such as average income, average production, or average sales.\n",
        "\n",
        "4️⃣ Foundation for Further Analysis:\n",
        "They serve as the basis for other statistical calculations and analyses, such as measures of dispersion (variance, standard deviation) and hypothesis testing.\n",
        "\n",
        "5️⃣ Identifies Central Position:\n",
        "They indicate the central or most common position of data, showing where the majority of observations lie.\n",
        "\n",
        "6️⃣ Helps to Detect Outliers:\n",
        "Comparing the mean and median can help detect outliers or extreme values in the data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_doTy0bb50CX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14 = What is variance, and how is it calculated ?\n",
        "\n",
        "Ans = Variance\n",
        "\n",
        "Definition:\n",
        "\n",
        "Variance is a measure of dispersion or spread in a set of data. It indicates how much the individual data values differ from the mean (average) of the dataset. In other words, variance shows how far the data points are spread out around the mean.\n",
        "\n",
        "A higher variance means the data points are more spread out, while a lower variance means they are closer to the mean.\n",
        "\n",
        "How Variance is Calculated:\n",
        "\n",
        "For a Population (Population Variance):\n",
        "\n",
        "\n",
        "1️⃣ Find the mean (\n",
        "𝑋\n",
        "ˉ\n",
        "X\n",
        "ˉ\n",
        " ) of all data values.\n",
        "2️⃣ Subtract the mean from each value to find the deviation for each value.\n",
        "3️⃣ Square each deviation to eliminate negative signs.\n",
        "4️⃣ Add up all the squared deviations.\n",
        "5️⃣ Divide by the total number of data values (N).\n",
        "\n",
        "Formula:\n",
        "\n",
        "𝜎\n",
        "2\n",
        "=\n",
        "∑\n",
        "(\n",
        "𝑋\n",
        "−\n",
        "𝑋\n",
        "ˉ\n",
        ")\n",
        "2\n",
        "𝑁\n",
        "σ\n",
        "2\n",
        " =\n",
        "N\n",
        "∑(X−\n",
        "X\n",
        "ˉ\n",
        " )\n",
        "2\n",
        "\n",
        "​\n",
        "\n",
        "Where:\n",
        "\n",
        "𝜎\n",
        "2\n",
        "σ\n",
        "2\n",
        "  = Population variance\n",
        "\n",
        "𝑋\n",
        "X = Each data value\n",
        "\n",
        "𝑋\n",
        "ˉ\n",
        "X\n",
        "ˉ\n",
        "  = Mean of the data\n",
        "\n",
        "𝑁\n",
        "N = Total number of data values"
      ],
      "metadata": {
        "id": "keyGLV9Z6DJH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 15 =  What is standard deviation, and why is it important ?\n",
        "\n",
        "Ans = Standard Deviation\n",
        "\n",
        "Definition:\n",
        "\n",
        "Standard deviation is a measure of dispersion that indicates how much the values in a dataset deviate from the mean (average). It is the square root of the variance, and it shows the average distance of each data point from the mean.\n",
        "\n",
        "In simple words, it tells us how spread out or close together the data values are.\n",
        "\n",
        "Importance of Standard Deviation:\n",
        "\n",
        "1️⃣ Measures Consistency:\n",
        "\n",
        "Standard deviation shows whether the data points are close to the mean (low standard deviation) or widely spread out (high standard deviation).\n",
        "\n",
        "2️⃣ Helps in Comparison:\n",
        "\n",
        "It allows comparison of variability between different datasets. For example, comparing the consistency of marks between two classes.\n",
        "\n",
        "3️⃣ Important in Research:\n",
        "\n",
        "Many statistical techniques, such as hypothesis testing and confidence intervals, rely on the standard deviation.\n",
        "\n",
        "4️⃣ Indicates Risk and Reliability:\n",
        "\n",
        "In fields like finance, standard deviation helps measure the risk or volatility of an investment.\n",
        "\n",
        "5️⃣ Easier Interpretation than Variance:\n",
        "\n",
        "Since standard deviation is in the same unit as the original data, it is easier to understand compared to variance, which is in squared units."
      ],
      "metadata": {
        "id": "4hkcUQtE6drH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 16 = Define and explain the term range in statistics ?\n",
        "\n",
        "Ans = Range\n",
        "\n",
        "Definition:\n",
        "\n",
        "The range is a simple measure of dispersion in statistics. It is defined as the difference between the highest and the lowest values in a dataset.\n",
        "\n",
        "In simple words, it shows how spread out the data values are from the smallest to the largest value.\n",
        "\n",
        "Formula:\n",
        "\n",
        "Range\n",
        "=\n",
        "Highest value\n",
        "−\n",
        "Lowest value\n",
        "Range=Highest value−Lowest value\n",
        "\n",
        "Explanation:\n",
        "\n",
        "The range indicates the spread or extent of the data.\n",
        "\n",
        "It is easy to calculate and understand.\n",
        "\n",
        "However, it only considers the two extreme values (maximum and minimum) and ignores the other data points, so it may not accurately reflect the true variability if there are outliers.\n",
        "\n",
        "Significance:\n",
        "\n",
        "Range gives a quick idea of the spread of data.\n",
        "\n",
        "It helps in comparing the variability between two datasets.\n",
        "\n",
        "It is often used as a basic measure of variability, especially when a quick estimate is needed.\n"
      ],
      "metadata": {
        "id": "OxRT7_Mu6vA_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 17 = What is the difference between variance and standard deviation ?\n",
        "\n",
        "Ans = Difference Between Variance and Standard Deviation\n",
        "\n",
        "1. Variance\n",
        "\n",
        "Definition:\n",
        "\n",
        "Variance is a measure of dispersion that indicates how far the data values spread out from the mean. It is calculated by taking the average of the squared deviations from the mean.\n",
        "\n",
        "Unit:\n",
        "\n",
        "The unit of variance is the square of the unit of the original data. For example, if data is in centimeters, the variance is in square centimeters (\n",
        "𝑐\n",
        "𝑚\n",
        "2\n",
        "cm\n",
        "2\n",
        " ).\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "Variance gives an idea about the degree of spread but is not directly interpretable because it is in squared units.\n",
        "\n",
        "2. Standard Deviation\n",
        "\n",
        "Definition:\n",
        "\n",
        "Standard deviation is the square root of the variance. It measures the average distance of each data point from the mean.\n",
        "\n",
        "Unit:\n",
        "The unit of standard deviation is the same as the original data, making it easier to understand and interpret.\n",
        "\n",
        "Interpretation:\n",
        "Standard deviation directly shows how much the data deviates from the mean on average. It is widely used in practical analysis."
      ],
      "metadata": {
        "id": "WTzuY6O-7Fd_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 18 = What is skewness in a dataset ?\n",
        "\n",
        "Ans = Skewness\n",
        "\n",
        "Definition:\n",
        "\n",
        "Skewness is a statistical measure that describes the degree of asymmetry of a distribution around its mean. In simple words, it tells us whether the data is symmetrically distributed or if it leans more towards one side (left or right).\n",
        "\n",
        "Types of Skewness:\n",
        "\n",
        "1️⃣ Positive Skewness (Right Skewed):\n",
        "\n",
        "The tail on the right side of the distribution is longer or fatter.\n",
        "\n",
        "Most data values are concentrated on the left of the mean, and a few high values pull the mean to the right.\n",
        "\n",
        "Example: Income distribution (few very high incomes raise the average).\n",
        "\n",
        "2️⃣ Negative Skewness (Left Skewed):\n",
        "\n",
        "The tail on the left side is longer or fatter.\n",
        "\n",
        "Most data values are concentrated on the right of the mean, and a few low values pull the mean to the left.\n",
        "\n",
        "Example: Age at retirement (most people retire at a similar age, with few retiring much earlier).\n",
        "\n",
        "3️⃣ Zero Skewness (Symmetrical Distribution):\n",
        "\n",
        "The data is perfectly symmetrical.\n",
        "\n",
        "The mean, median, and mode are all equal.\n",
        "\n",
        "Example: Ideal normal distribution (bell curve).\n",
        "\n"
      ],
      "metadata": {
        "id": "KO0KvjmN7b6W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 19 = What does it mean if a dataset is positively or negatively skewed ?\n",
        "\n",
        "Ans= Meaning of Positive and Negative Skewness\n",
        "\n",
        "1. Positively Skewed Data (Right-Skewed)\n",
        "\n",
        "Meaning:\n",
        "\n",
        "A dataset is said to be positively skewed if the tail on the right side of the distribution is longer or fatter than the left side. This means that there are a few unusually large values pulling the mean to the right.\n",
        "\n",
        "Characteristics:\n",
        "\n",
        "Most data values are concentrated on the left side (lower values).\n",
        "\n",
        "The mean is greater than the median.\n",
        "\n",
        "The mode is less than the median.\n",
        "\n",
        "Example:\n",
        "\n",
        "Income distribution in a population (most people earn average salaries, but a few people earn very high salaries).\n",
        "\n",
        "Marks of students in a very easy test where most students score high but a few score very low.\n",
        "\n",
        "2. Negatively Skewed Data (Left-Skewed)\n",
        "\n",
        "Meaning:\n",
        "\n",
        "A dataset is said to be negatively skewed if the tail on the left side of the distribution is longer or fatter than the right side. This indicates that there are a few unusually low values pulling the mean to the left.\n",
        "\n",
        "Characteristics:\n",
        "\n",
        "Most data values are concentrated on the right side (higher values).\n",
        "\n",
        "The mean is less than the median.\n",
        "\n",
        "The mode is greater than the median.\n",
        "\n",
        "Example:\n",
        "\n",
        "Age at retirement (most people retire around a certain age, but a few retire very early).\n",
        "\n",
        "Scores in a very difficult exam where most students get low marks but a few get very high marks."
      ],
      "metadata": {
        "id": "Lxea0A-f7pTn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 20 = Define and explain kurtosis ?\n",
        "\n",
        "Ans = Kurtosis\n",
        "\n",
        "Definition:\n",
        "\n",
        "Kurtosis is a statistical measure that describes the degree of peakedness or flatness of a data distribution compared to a normal distribution. In simple words, kurtosis indicates whether the data have heavy tails or light tails, and whether the peak is sharper or flatter than a normal bell-shaped curve.\n",
        "\n",
        "Kurtosis measures how peaked or flat a data distribution is, compared to a normal distribution, and tells us about the likelihood of extreme values.\n",
        "\n",
        "Importance of Kurtosis:\n",
        "\n",
        "Kurtosis helps identify the probability of outliers in a dataset.\n",
        "\n",
        "It is useful in risk management, quality control, and financial analysis.\n",
        "\n",
        "It helps compare whether a dataset is more or less extreme than a normal distribution."
      ],
      "metadata": {
        "id": "QinUdUbJ79U_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 21 = What is the purpose of covariance ?\n",
        "\n",
        "Ans =  Covariance\n",
        "\n",
        "Definition:\n",
        "\n",
        "Covariance is a statistical measure that indicates the direction of the relationship between two variables. It shows whether two variables change together (vary together) and in which direction — whether they increase or decrease together.\n",
        "\n",
        "Purpose of Covariance:\n",
        "\n",
        "1️⃣ To Measure the Direction of Relationship:\n",
        "\n",
        "Covariance helps determine whether the two variables have a positive or negative relationship:\n",
        "\n",
        "Positive covariance: When one variable increases, the other tends to increase as well.\n",
        "\n",
        "Negative covariance: When one variable increases, the other tends to decrease.\n",
        "\n",
        "2️⃣ To Understand Joint Variability:\n",
        "\n",
        "Covariance shows how two variables vary jointly with respect to their means. It quantifies how much they change together.\n",
        "\n",
        "3️⃣ Basis for Correlation:\n",
        "\n",
        "Covariance is the foundation for calculating correlation, which standardizes the relationship to a fixed range (from -1 to +1). Correlation is easier to interpret, but it is based on the covariance value.\n",
        "\n",
        "4️⃣ Useful in Portfolio Theory (Finance):\n",
        "\n",
        "In finance, covariance is used to analyze how two assets move together. It helps in portfolio diversification by selecting assets with low or negative covariance to reduce overall risk.\n",
        "\n",
        "5️⃣ Helps in Multivariate Analysis:\n",
        "\n",
        "Covariance is an important component in statistics and data science for techniques like Principal Component Analysis (PCA) and multiple regression, where understanding the relationships among variables is essential.\n",
        "\n"
      ],
      "metadata": {
        "id": "VVJzSYIlO5uP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 22 = What does correlation measure in statistics ?\n",
        "\n",
        "Ans = Definition:\n",
        "\n",
        "Correlation is a statistical measure that describes the strength and direction of a linear relationship between two variables. It shows how closely the variables move together and whether they change in the same or opposite direction.\n",
        "\n",
        "What Correlation Measures:\n",
        "\n",
        "1️⃣ Direction of Relationship:\n",
        "\n",
        "Correlation indicates whether the relationship between two variables is positive, negative, or zero:\n",
        "\n",
        "Positive Correlation: Both variables increase or decrease together.\n",
        "\n",
        "Negative Correlation: One variable increases while the other decreases.\n",
        "\n",
        "Zero Correlation: No linear relationship exists between the variables.\n",
        "\n",
        "2️⃣ Strength of Relationship:\n",
        "\n",
        "Correlation quantifies how strong or weak the relationship is:\n",
        "\n",
        "A correlation close to +1 indicates a strong positive linear relationship.\n",
        "\n",
        "A correlation close to -1 indicates a strong negative linear relationship.\n",
        "\n",
        "A correlation close to 0 indicates a very weak or no linear relationship.\n",
        "\n",
        "Importance of Correlation:\n",
        "\n",
        "It helps in predicting the value of one variable based on another.\n",
        "\n",
        "It is widely used in research, business, and economics to analyze relationships between factors.\n",
        "\n",
        "It helps in determining whether further analysis (like regression) is useful."
      ],
      "metadata": {
        "id": "nm0WJewtPoLs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 23 = What is the difference between covariance and correlation ?\n",
        "\n",
        "Ans = Covariance\n",
        "\n",
        "Definition:\n",
        "\n",
        "Covariance is a statistical measure that indicates the direction of the linear relationship between two variables. It shows whether the variables increase or decrease together.\n",
        "\n",
        "Characteristics:\n",
        "\n",
        "Covariance can have any numerical value, positive or negative.\n",
        "\n",
        "A positive covariance means both variables tend to increase or decrease together.\n",
        "\n",
        "A negative covariance means one variable increases while the other decreases.\n",
        "\n",
        "The magnitude of covariance depends on the units of measurement, so it is not standardised and can be difficult to interpret directly.\n",
        "\n",
        "Correlation\n",
        "\n",
        "Definition:\n",
        "\n",
        "Correlation is a statistical measure that describes both the strength and direction of the linear relationship between two variables. It is a scaled or standardised form of covariance.\n",
        "\n",
        "Characteristics:\n",
        "\n",
        "Correlation is dimensionless and always ranges between -1 and +1.\n",
        "\n",
        "A correlation of +1 indicates a perfect positive linear relationship.\n",
        "\n",
        "A correlation of -1 indicates a perfect negative linear relationship.\n",
        "\n",
        "A correlation of 0 indicates no linear relationship.\n",
        "\n",
        "Correlation is not affected by the units of measurement, making it easier to compare relationships between different pairs of variables."
      ],
      "metadata": {
        "id": "d09sjQ6ZP_L9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 24 = What are some real-world applications of statistics ?\n",
        "\n",
        "Ans = Statistics plays a crucial role in almost every field of life. It helps in collecting, analyzing, interpreting, and presenting data for better decision-making. Here are some important real-world applications:\n",
        "\n",
        "\n",
        "1. Business and Industry\n",
        "\n",
        "Statistics is used for market research, product quality control, and forecasting sales and demand.\n",
        "\n",
        "Companies use statistical tools to analyze consumer preferences and improve products and services.\n",
        "\n",
        "It helps in inventory management and setting production targets.\n",
        "\n",
        "2️⃣ Government and Administration\n",
        "\n",
        "Governments use statistics for census surveys, economic planning, unemployment rates, literacy rates, and population growth studies.\n",
        "\n",
        "It is vital in policy formulation and allocation of resources for welfare schemes.\n",
        "\n",
        "3️⃣ Education\n",
        "\n",
        "Statistics helps analyze students’ performance through exam scores, grading systems, and result analysis.\n",
        "\n",
        "It is used to improve teaching methods based on feedback and test results.\n",
        "\n",
        "4️⃣ Medicine and Health Care\n",
        "\n",
        "In medical research, statistics is used to test the effectiveness of new drugs and treatments.\n",
        "\n",
        "Hospitals use statistical data to monitor patient recovery rates, disease prevalence, and resource planning.\n",
        "\n",
        "5️⃣ Agriculture\n",
        "\n",
        "Statistics is used in agricultural experiments to find the best farming techniques and analyze crop yields.\n",
        "\n",
        "It helps in forecasting agricultural production and planning for food supply.\n",
        "\n",
        "6️⃣ Economics and Finance\n",
        "\n",
        "Economists use statistics to study national income, inflation rates, economic growth, and trends.\n",
        "\n",
        "In finance, statistics is used for risk analysis, stock market predictions, and investment planning.\n",
        "\n",
        "7️⃣ Sports\n",
        "\n",
        "Statistics helps analyze players’ performance, team rankings, and game strategies.\n",
        "\n",
        "It is widely used in decision-making during matches and in player selection.\n",
        "\n",
        "8️⃣ Social Sciences and Research\n",
        "\n",
        "Researchers use statistical methods to collect and analyze data in psychology, sociology, and other social sciences.\n",
        "\n",
        "It helps in drawing valid conclusions from sample surveys and experiments."
      ],
      "metadata": {
        "id": "ZJbvCcvHSzs0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PRACTICAL QUESTIONS"
      ],
      "metadata": {
        "id": "4ECE5aa6Tmt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 = How do you calculate the mean, median, and mode of a dataset ?\n",
        "\n",
        "# Import necessary libraries\n",
        "# import numpy as np\n",
        "\n",
        "# import statistics as stats\n",
        "# from scipy import stats as scipy_stats\n",
        "\n",
        "# Example dataset\n",
        "data = [2, 4, 4, 4, 5, 5, 7, 9]\n",
        "\n",
        "# 1️⃣ Mean (Average)\n",
        "# mean = np.mean(data)\n",
        "\n",
        "# print(\"Mean:\", mean)\n",
        "\n",
        "# 2️⃣ Median (Middle value)\n",
        "# median = np.median(data)\n",
        "# print(\"Median:\", median)\n",
        "\n",
        "# 3️⃣ Mode (Most frequent value)\n",
        "# mode = scipy_stats.mode(data, keepdims=True)  # scipy version for robust handling\n",
        "# print(\"Mode:\", mode.mode[0], \" (Count:\", mode.count[0], \")\")\n",
        "\n",
        "# Alternatively, you can use the statistics module:\n",
        "# mode2 = stats.mode(data)\n",
        "# print(\"Mode using statistics module:\", mode2)"
      ],
      "metadata": {
        "id": "plRUJFBEcvlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2 Write a Python program to compute the variance and standard deviation of a dataset ?\n",
        "# Import necessary libraries\n",
        "# import numpy as np\n",
        "# import statistics as stats\n",
        "\n",
        "# Example dataset\n",
        "# data = [2, 4, 4, 4, 5, 5, 7, 9]\n",
        "\n",
        "# 1️⃣ Variance\n",
        "# Using numpy\n",
        "# variance = np.var(data)  # Population variance\n",
        "# variance_sample = np.var(data, ddof=1)  # Sample variance\n",
        "\n",
        "# print(\"Population Variance:\", variance)\n",
        "# print(\"Sample Variance:\", variance_sample)\n",
        "\n",
        "# Using statistics module (for sample variance)\n",
        "# variance_stats = stats.variance(data)\n",
        "# print(\"Sample Variance (statistics module):\", variance_stats)\n",
        "\n",
        "# 2️⃣ Standard Deviation\n",
        "# Using numpy\n",
        "# std_dev = np.std(data)  # Population standard deviation\n",
        "# std_dev_sample = np.std(data, ddof=1)  # Sample standard deviation\n",
        "\n",
        "# print(\"Population Standard Deviation:\", std_dev)\n",
        "# print(\"Sample Standard Deviation:\", std_dev_sample)\n",
        "\n",
        "# Using statistics module (for sample standard deviation)\n",
        "# std_dev_stats = stats.stdev(data)\n",
        "# print(\"Sample Standard Deviation (statistics module):\", std_dev_stats)"
      ],
      "metadata": {
        "id": "5ghPpcMDYrR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3 Create a dataset and classify it into nominal, ordinal, interval, and ratio types ?\n",
        "import pandas as pd\n",
        "\n",
        "# Create a simple dataset\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
        "    'Education Level': ['High School', 'Bachelor', 'Master', 'PhD', 'Bachelor'],\n",
        "    'Temperature (°C)': [37, 40, 35, 42, 38],\n",
        "    'Height (cm)': [160, 175, 168, 180, 158]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq6VuUB2ZJy7",
        "outputId": "9b821203-549e-4112-d9f8-a7550dcf17fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Name Education Level  Temperature (°C)  Height (cm)\n",
            "0    Alice     High School                37          160\n",
            "1      Bob        Bachelor                40          175\n",
            "2  Charlie          Master                35          168\n",
            "3    David             PhD                42          180\n",
            "4      Eva        Bachelor                38          158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4 Implement sampling techniques like random sampling and stratified sampling ?\n",
        "#import pandas as pd\n",
        "#import numpy as np\n",
        "\n",
        "# Create a simple dataset\n",
        "    # np.random.seed(42)  # For reproducibility\n",
        "\n",
        "# data = {\n",
        "  #  'ID': range(1, 21),\n",
        "   # 'Category': ['A']*5 + ['B']*5 + ['C']*5 + ['D']*5,\n",
        "    #'Value': np.random.randint(10, 100, 20)\n",
        "#}\n",
        "\n",
        "#df = pd.DataFrame(data)\n",
        "#print(df)\n",
        "\n",
        "# Random Sampling - pick 5 random rows\n",
        "#random_sample = df.sample(n=5, random_state=42)\n",
        "# print(\"Random Sample:\\n\", random_sample)\n",
        "\n",
        " #Stratified Sampling - 50% of data while keeping category ratio same\n",
        "#stratified_sample, _ = train_test_split(\n",
        " #   df,\n",
        "  #  test_size=0.5,  # Keep 50% for sample\n",
        "   # stratify=df['Category'],\n",
        "    #random_state=42\n",
        "\n",
        "\n",
        "#print(\"Stratified Sample:\\n\", stratified_sample)\n",
        "\n"
      ],
      "metadata": {
        "id": "763vCJ2fZhWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5 Write a Python function to calculate the range of a dataset ?\n",
        "#def calculate_range(data):\n",
        " #   \"\"\"Calculate the range of a dataset\"\"\"\n",
        "  #  if not data:\n",
        "   #     return None\n",
        "    #data_range = max(data) - min(data)\n",
        "   # return data_range\n",
        "\n",
        "# Example dataset\n",
        "#dataset = [12, 45, 67, 23, 89, 34, 56]\n",
        "\n",
        "# Call the function and print the result\n",
        "# range_value = calculate_range(dataset)\n",
        "#print(\"Dataset:\", dataset)\n",
        "#print(\"Range of dataset:\", range_value)\n"
      ],
      "metadata": {
        "id": "_RtOlPyEaPfL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6 Create a dataset and plot its histogram to visualize skewness ?\n",
        "#import numpy as np\n",
        "#import matplotlib.pyplot as plt\n",
        "#import seaborn as sns\n",
        "#from scipy.stats import skew\n",
        "\n",
        "# Create a positively skewed dataset (right-skewed)\n",
        "#data = np.random.exponential(scale=2, size=1000)\n",
        "\n",
        "# Calculate skewness\n",
        "#skewness_value = skew(data)\n",
        "\n",
        "# Plot histogram\n",
        "#plt.figure(figsize=(8, 5))\n",
        "#sns.histplot(data, bins=30, kde=True, color='skyblue')\n",
        "#plt.title(f\"Histogram of Dataset (Skewness = {skewness_value:.2f})\")\n",
        "#plt.xlabel(\"Value\")\n",
        "#plt.ylabel(\"Frequency\")\n",
        "#plt.grid(True)\n",
        "#plt.show()\n",
        "\n",
        "# Print skewness value\n",
        "#print(\"Skewness of the dataset:\", skewness_value)"
      ],
      "metadata": {
        "id": "vSZycCQMy5K-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7 Calculate skewness and kurtosis of a dataset using Python libraries ?\n",
        "#import numpy as np\n",
        "#from scipy.stats import skew, kurtosis\n",
        "\n",
        "# Create a sample dataset (right-skewed)\n",
        "#data = np.random.exponential(scale=2, size=1000)\n",
        "\n",
        "# Calculate skewness\n",
        "#skewness_value = skew(data)\n",
        "\n",
        "# Calculate kurtosis (Fisher's definition, normal ==> 0)\n",
        "#kurtosis_value = kurtosis(data)\n",
        "\n",
        "# Print results\n",
        "#print(\"Dataset (first 10 values):\", data[:10])\n",
        "#print(\"Skewness of dataset:\", skewness_value)\n",
        "#print(\"Kurtosis of dataset:\", kurtosis_value)"
      ],
      "metadata": {
        "id": "xoZNhPs6zYNl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8 =Generate a dataset and demonstrate positive and negative skewness ?\n",
        "#import numpy as np\n",
        "#import matplotlib.pyplot as plt\n",
        "#import seaborn as sns\n",
        "#from scipy.stats import skew\n",
        "\n",
        "# Generate datasets\n",
        "#np.random.seed(42)\n",
        "\n",
        "# Positively skewed data (exponential)\n",
        "#positive_skew_data = np.random.exponential(scale=2, size=1000)\n",
        "\n",
        "# Negatively skewed data (flip of exponential)\n",
        "#negative_skew_data = -np.random.exponential(scale=2, size=1000)\n",
        "\n",
        "# Calculate skewness\n",
        "#positive_skew = skew(positive_skew_data)\n",
        "#negative_skew = skew(negative_skew_data)\n",
        "\n",
        "# Plotting\n",
        "#plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Positive skew plot\n",
        "#plt.subplot(1, 2, 1)\n",
        "#sns.histplot(positive_skew_data, bins=30, kde=True, color='skyblue')\n",
        "#plt.title(f'Positive Skew (Skewness = {positive_skew:.2f})')\n",
        "#plt.xlabel('Value')\n",
        "#plt.ylabel('Frequency')\n",
        "\n",
        "# Negative skew plot\n",
        "#plt.subplot(1, 2, 2)\n",
        "#sns.histplot(negative_skew_data, bins=30, kde=True, color='salmon')\n",
        "#plt.title(f'Negative Skew (Skewness = {negative_skew:.2f})')\n",
        "#plt.xlabel('Value')\n",
        "#plt.ylabel('Frequency')\n",
        "\n",
        "#plt.tight_layout()\n",
        "#plt.show()\n",
        "\n",
        "# Print values\n",
        "#print(\"Skewness of positive skewed dataset:\", positive_skew)\n",
        "#print(\"Skewness of negative skewed dataset:\", negative_skew)"
      ],
      "metadata": {
        "id": "tp_NClVpzl_E"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9  Write a Python script to calculate covariance between two datasets ?\n",
        "#import numpy as np\n",
        "\n",
        "# Example datasets\n",
        "#x = [10, 20, 30, 40, 50]\n",
        "#y = [15, 25, 35, 45, 60]\n",
        "\n",
        "# Method 1: Manual calculation of covariance\n",
        "#def calculate_covariance(x, y):\n",
        " #   n = len(x)\n",
        " #   mean_x = np.mean(x)\n",
        " #   mean_y = np.mean(y)\n",
        " #   covariance = sum((x[i] - mean_x) * (y[i] - mean_y) for i in range(n)) / (n - 1)\n",
        " #   return covariance\n",
        "\n",
        "# Method 2: Using NumPy's cov() function\n",
        "#cov_matrix = np.cov(x, y, bias=False)  # bias=False uses (n-1) in denominator\n",
        "#numpy_cov = cov_matrix[0, 1]\n",
        "\n",
        "# Output\n",
        "#print(\"Dataset X:\", x)\n",
        "#print(\"Dataset Y:\", y)\n",
        "#print(\"\\nManual Covariance Calculation:\", calculate_covariance(x, y))\n",
        "#print(\"Covariance using NumPy:\", numpy_cov)"
      ],
      "metadata": {
        "id": "vkKlU_sLz8ld"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10 Write a Python script to calculate the correlation coefficient between two datasets ?\n",
        "# import numpy as np\n",
        "\n",
        "# Example datasets\n",
        "#x = [10, 20, 30, 40, 50]\n",
        "#y = [15, 25, 35, 45, 60]\n",
        "\n",
        "# Method 1: Manual calculation of Pearson correlation\n",
        "#def calculate_correlation(x, y):\n",
        "#    x = np.array(x)\n",
        "#    y = np.array(y)\n",
        "#    mean_x = np.mean(x)\n",
        "#    mean_y = np.mean(y)\n",
        "\n",
        "#    numerator = np.sum((x - mean_x) * (y - mean_y))\n",
        "#    denominator = np.sqrt(np.sum((x - mean_x)**2) * np.sum((y - mean_y)**2))\n",
        "\n",
        "#    return numerator / denominator\n",
        "\n",
        "# Method 2: Using NumPy's corrcoef() function\n",
        "#corr_matrix = np.corrcoef(x, y)\n",
        "#numpy_corr = corr_matrix[0, 1]\n",
        "\n",
        "# Output\n",
        "#print(\"Dataset X:\", x)\n",
        "#print(\"Dataset Y:\", y)\n",
        "#print(\"\\nManual Correlation Coefficient:\", calculate_correlation(x, y))\n",
        "#print(\"Correlation using NumPy:\", numpy_corr)"
      ],
      "metadata": {
        "id": "03CRy4D60M_U"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11 Create a scatter plot to visualize the relationship between two variables ?\n",
        "\n",
        "#import matplotlib.pyplot as plt\n",
        "#import seaborn as sns\n",
        "\n",
        "# Sample data\n",
        "#x = [10, 20, 30, 40, 50]\n",
        "#y = [15, 25, 35, 45, 60]\n",
        "\n",
        "# Create scatter plot\n",
        "#plt.figure(figsize=(6, 5))\n",
        "#sns.scatterplot(x=x, y=y, color='blue', s=100)\n",
        "\n",
        "# Add labels and title\n",
        "#plt.title(\"Scatter Plot of X vs Y\", fontsize=14)\n",
        "#plt.xlabel(\"X Variable\", fontsize=12)\n",
        "#plt.ylabel(\"Y Variable\", fontsize=12)\n",
        "#plt.grid(True)\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "T-7xiQ8j0kc0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12 Implement and compare simple random sampling and systematic sampling ?\n",
        "\n",
        "#import numpy as np\n",
        "#import pandas as pd\n",
        "#import matplotlib.pyplot as plt\n",
        "#import seaborn as sns\n",
        "\n",
        "# Step 1: Create a sample dataset\n",
        "#np.random.seed(42)\n",
        "#data = pd.DataFrame({\n",
        "#    'ID': range(1, 101),\n",
        "#    'Score': np.random.randint(50, 100, size=100)\n",
        "#})\n",
        "\n",
        "#print(\"Original Dataset (first 5 rows):\")\n",
        "#print(data.head())\n",
        "\n",
        "# Step 2: Simple Random Sampling (select 10 samples randomly)\n",
        "#simple_random_sample = data.sample(n=10, random_state=42)\n",
        "\n",
        "# Step 3: Systematic Sampling (every k-th element, k = population/sample_size)\n",
        "#def systematic_sampling(df, n):\n",
        "#    k = len(df) // n\n",
        "#    start = np.random.randint(0, k)\n",
        "#    return df.iloc[start::k][:n]\n",
        "\n",
        "#systematic_sample = systematic_sampling(data, 10)\n",
        "\n",
        "# Step 4: Compare samples\n",
        "#print(\"\\nSimple Random Sample:\")\n",
        "#print(simple_random_sample)\n",
        "\n",
        "#print(\"\\nSystematic Sample:\")\n",
        "#print(systematic_sample)\n",
        "\n",
        "# Step 5: Visual Comparison\n",
        "#plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Simple Random Sample Plot\n",
        "#plt.subplot(1, 2, 1)\n",
        "#sns.barplot(x=simple_random_sample['ID'], y=simple_random_sample['Score'], palette='Blues_d')\n",
        "#plt.title(\"Simple Random Sampling\")\n",
        "#plt.xlabel(\"ID\")\n",
        "#plt.ylabel(\"Score\")\n",
        "\n",
        "# Systematic Sample Plot\n",
        "#plt.subplot(1, 2, 2)\n",
        "#sns.barplot(x=systematic_sample['ID'], y=systematic_sample['Score'], palette='Greens_d')\n",
        "#plt.title(\"Systematic Sampling\")\n",
        "#plt.xlabel(\"ID\")\n",
        "#plt.ylabel(\"Score\")\n",
        "\n",
        "#plt.tight_layout()\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "xJqYyu2q06SU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 13 Calculate the mean, median, and mode of grouped data ?\n",
        "#import pandas as pd\n",
        "#import numpy as np\n",
        "#from scipy.stats import mode\n",
        "\n",
        "# Step 1: Define class intervals and frequencies\n",
        "#data = {\n",
        "#    'Class Interval': ['0-10', '10-20', '20-30', '30-40', '40-50'],\n",
        "#    'Frequency': [5, 8, 15, 16, 6]\n",
        "#}\n",
        "\n",
        "#df = pd.DataFrame(data)\n",
        "\n",
        "# Step 2: Calculate class midpoints\n",
        "#def get_midpoint(interval):\n",
        "#    low, high = map(int, interval.split('-'))\n",
        "#    return (low + high) / 2\n",
        "\n",
        "#df['Midpoint'] = df['Class Interval'].apply(get_midpoint)\n",
        "\n",
        "# Step 3: Calculate Mean\n",
        "#df['f * x'] = df['Frequency'] * df['Midpoint']\n",
        "#mean = df['f * x'].sum() / df['Frequency'].sum()\n",
        "\n",
        "# Step 4: Calculate Median (using grouped data formula)\n",
        "#cumulative_freq = df['Frequency'].cumsum()\n",
        "#total_freq = df['Frequency'].sum()\n",
        "#median_class_index = np.where(cumulative_freq >= total_freq / 2)[0][0]\n",
        "\n",
        "#L = int(df.loc[median_class_index, 'Class Interval'].split('-')[0])\n",
        "#F = df.loc[median_class_index, 'Frequency']\n",
        "#CF = cumulative_freq[median_class_index - 1] if median_class_index != 0 else 0\n",
        "#h = 10  # class width\n",
        "\n",
        "#median = L + ((total_freq / 2 - CF) / F) * h\n",
        "\n",
        "# Step 5: Calculate Mode (grouped formula)\n",
        "#modal_class_index = df['Frequency'].idxmax()\n",
        "#L = int(df.loc[modal_class_index, 'Class Interval'].split('-')[0])\n",
        "#f1 = df.loc[modal_class_index, 'Frequency']\n",
        "#f0 = df.loc[modal_class_index - 1, 'Frequency'] if modal_class_index != 0 else 0\n",
        "#f2 = df.loc[modal_class_index + 1, 'Frequency'] if modal_class_index + 1 < len(df) else 0\n",
        "\n",
        "#mode_value = L + ((f1 - f0) / ((2 * f1) - f0 - f2)) * h\n",
        "\n",
        "# Step 6: Display Results\n",
        "#print(\"Grouped Data Table:\")\n",
        "#print(df)\n",
        "\n",
        "#print(f\"\\nMean: {mean:.2f}\")\n",
        "#print(f\"Median: {median:.2f}\")\n",
        "#print(f\"Mode: {mode_value:.2f}\")"
      ],
      "metadata": {
        "id": "gAEXzjcV1X7N"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 14 Simulate data using Python and calculate its central tendency and dispersion ?\n",
        "\n",
        "#import numpy as np\n",
        "#import pandas as pd\n",
        "#from scipy import stats\n",
        "\n",
        "# Step 1: Simulate data (e.g., 100 students' marks out of 100)\n",
        "#np.random.seed(42)\n",
        "#data = np.random.normal(loc=70, scale=10, size=100)  # mean=70, std=10\n",
        "#data = np.round(data, 2)\n",
        "\n",
        "# Convert to DataFrame\n",
        "#df = pd.DataFrame(data, columns=[\"Marks\"])\n",
        "\n",
        "# Step 2: Central Tendency\n",
        "#mean = np.mean(data)\n",
        "#median = np.median(data)\n",
        "#mode = stats.mode(data, keepdims=True)[0][0]\n",
        "\n",
        "# Step 3: Dispersion\n",
        "#data_range = np.max(data) - np.min(data)\n",
        "#variance = np.var(data, ddof=1)\n",
        "#std_dev = np.std(data, ddof=1)\n",
        "#iqr = stats.iqr(data)\n",
        "\n",
        "# Step 4: Display Results\n",
        "#print(\"First 10 Data Points:\\n\", df.head(10), \"\\n\")\n",
        "\n",
        "#print(\"📌 Central Tendency\")\n",
        "#print(f\"Mean: {mean:.2f}\")\n",
        "#print(f\"Median: {median:.2f}\")\n",
        "#print(f\"Mode: {mode:.2f}\")\n",
        "\n",
        "#print(\"\\n📊 Dispersion Measures\")\n",
        "#print(f\"Range: {data_range:.2f}\")\n",
        "#print(f\"Variance: {variance:.2f}\")\n",
        "#print(f\"Standard Deviation: {std_dev:.2f}\")\n",
        "#print(f\"Interquartile Range (IQR): {iqr:.2f}\")"
      ],
      "metadata": {
        "id": "FmVYzFgI1-pV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 15 Use NumPy or pandas to summarize a dataset’s descriptive statistics ?\n",
        "\n",
        "#import numpy as np\n",
        "#import pandas as pd\n",
        "\n",
        "# Step 1: Simulate data (e.g., age of 50 people)\n",
        "#np.random.seed(0)\n",
        "#ages = np.random.randint(18, 60, size=50)\n",
        "\n",
        "# Convert to pandas DataFrame\n",
        "#df = pd.DataFrame(ages, columns=[\"Age\"])\n",
        "\n",
        "# Step 2: Summary using pandas .describe()\n",
        "#print(\"📊 Descriptive Statistics using pandas:\")\n",
        "#print(df.describe())\n",
        "\n",
        "# Step 3: Manual descriptive stats using NumPy\n",
        "#mean = np.mean(ages)\n",
        "#median = np.median(ages)\n",
        "#mode = df['Age'].mode().values[0]\n",
        "#std_dev = np.std(ages, ddof=1)\n",
        "#variance = np.var(ages, ddof=1)\n",
        "#range_val = np.max(ages) - np.min(ages)\n",
        "#iqr = np.percentile(ages, 75) - np.percentile(ages, 25)\n",
        "\n",
        "# Step 4: Print detailed stats\n",
        "#print(\"\\n📌 Manual Descriptive Stats using NumPy:\")\n",
        "#print(f\"Mean: {mean:.2f}\")\n",
        "#print(f\"Median: {median}\")\n",
        "#print(f\"Mode: {mode}\")\n",
        "#print(f\"Standard Deviation: {std_dev:.2f}\")\n",
        "#print(f\"Variance: {variance:.2f}\")\n",
        "#print(f\"Range: {range_val}\")\n",
        "#print(f\"IQR (Interquartile Range): {iqr}\")"
      ],
      "metadata": {
        "id": "y899-emu2mbM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 16 Plot a boxplot to understand the spread and identify outliers ?\n",
        "\n",
        "#import numpy as np\n",
        "#import pandas as pd\n",
        "#import seaborn as sns\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Simulate data (e.g., students' scores)\n",
        "#np.random.seed(0)\n",
        "#scores = np.append(np.random.normal(70, 10, 48), [30, 100])  # 2 outliers added\n",
        "\n",
        "# Step 2: Convert to DataFrame\n",
        "#df = pd.DataFrame(scores, columns=['Score'])\n",
        "\n",
        "# Step 3: Boxplot\n",
        "#plt.figure(figsize=(6, 5))\n",
        "#sns.boxplot(x=df['Score'], color='skyblue')\n",
        "#plt.title(\"Boxplot of Scores\")\n",
        "#plt.xlabel(\"Score\")\n",
        "#plt.grid(True)\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "Jx82gBXf3M6M"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 17 Calculate the interquartile range (IQR) of a dataset ?\n",
        "\n",
        "#import numpy as np\n",
        "#from scipy.stats import iqr\n",
        "\n",
        "# Step 1: Create or simulate a dataset\n",
        "#np.random.seed(0)\n",
        "#data = np.random.randint(10, 100, size=20)  # Random integers from 10 to 100\n",
        "\n",
        "#print(\"Dataset:\", data)\n",
        "\n",
        "# Step 2: Method 1 – Calculate IQR manually using percentiles\n",
        "#Q1 = np.percentile(data, 25)\n",
        "#Q3 = np.percentile(data, 75)\n",
        "#iqr_manual = Q3 - Q1\n",
        "\n",
        "# Step 3: Method 2 – Using SciPy's iqr function\n",
        "#iqr_scipy = iqr(data)\n",
        "\n",
        "# Step 4: Print Results\n",
        "#print(f\"\\nQ1 (25th percentile): {Q1}\")\n",
        "#print(f\"Q3 (75th percentile): {Q3}\")\n",
        "#print(f\"IQR (Manual Calculation): {iqr_manual}\")\n",
        "#print(f\"IQR (Using SciPy): {iqr_scipy}\")"
      ],
      "metadata": {
        "id": "Q9v1bBbw3hK0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 18  Implement Z-score normalization and explain its significance ?\n",
        "\n",
        "#import numpy as np\n",
        "#import pandas as pd\n",
        "#from scipy.stats import zscore\n",
        "\n",
        "# Step 1: Simulate a dataset (e.g., test scores)\n",
        "#np.random.seed(42)\n",
        "#data = np.random.randint(50, 100, size=10)\n",
        "\n",
        "# Convert to DataFrame\n",
        "#df = pd.DataFrame({'Original_Scores': data})\n",
        "\n",
        "# Step 2: Implement Z-score normalization manually\n",
        "#mean = np.mean(data)\n",
        "#std = np.std(data, ddof=1)\n",
        "#df['Z_Manual'] = (df['Original_Scores'] - mean) / std\n",
        "\n",
        "# Step 3: Use SciPy to calculate Z-scores\n",
        "#df['Z_Scipy'] = zscore(data)\n",
        "\n",
        "# Step 4: Display the results\n",
        "#print(\"Z-score Normalization:\")\n",
        "#print(df)"
      ],
      "metadata": {
        "id": "5j57blGQ3vRk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 19 Compare two datasets using their standard deviations ?\n",
        "\n",
        "#import numpy as np\n",
        "#import pandas as pd\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Create two datasets\n",
        "#np.random.seed(0)\n",
        "\n",
        "# Dataset A: low variability (std ~5)\n",
        "#data_a = np.random.normal(loc=70, scale=5, size=100)\n",
        "\n",
        "# Dataset B: high variability (std ~15)\n",
        "#data_b = np.random.normal(loc=70, scale=15, size=100)\n",
        "\n",
        "# Step 2: Create a DataFrame\n",
        "#df = pd.DataFrame({\n",
        "#    'Dataset A': data_a,\n",
        "#    'Dataset B': data_b\n",
        "#})\n",
        "\n",
        "# Step 3: Calculate standard deviation\n",
        "#std_a = np.std(data_a, ddof=1)\n",
        "#std_b = np.std(data_b, ddof=1)\n",
        "\n",
        "# Step 4: Display results\n",
        "#print(\"Standard Deviation of Dataset A:\", round(std_a, 2))\n",
        "#print(\"Standard Deviation of Dataset B:\", round(std_b, 2))\n",
        "\n",
        "# Step 5: Visualize the comparison\n",
        "#plt.figure(figsize=(8, 5))\n",
        "#plt.hist(data_a, bins=20, alpha=0.7, label='Dataset A (low SD)', color='skyblue')\n",
        "#plt.hist(data_b, bins=20, alpha=0.5, label='Dataset B (high SD)', color='orange')\n",
        "#plt.title(\"Comparison of Dataset Spread using Histograms\")\n",
        "#plt.xlabel(\"Value\")\n",
        "#plt.ylabel(\"Frequency\")\n",
        "#plt.legend()\n",
        "#plt.grid(True)\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "swqbd8YR38Tz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 20 Write a Python program to visualize covariance using a heatmap ?\n",
        "\n",
        "#import numpy as np\n",
        "#import pandas as pd\n",
        "#import seaborn as sns\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Create a sample dataset (3 variables)\n",
        "#np.random.seed(1)\n",
        "#data = pd.DataFrame({\n",
        "#    'Math_Score': np.random.normal(70, 10, 100),\n",
        "#    'Science_Score': np.random.normal(72, 12, 100),\n",
        "#    'English_Score': np.random.normal(68, 8, 100)\n",
        "#})\n",
        "\n",
        "# Step 2: Calculate Covariance Matrix\n",
        "#cov_matrix = data.cov()\n",
        "#print(\"Covariance Matrix:\\n\")\n",
        "#print(cov_matrix)\n",
        "\n",
        "# Step 3: Plot Heatmap of Covariance\n",
        "#plt.figure(figsize=(8, 6))\n",
        "#sns.heatmap(cov_matrix, annot=True, cmap='YlGnBu', fmt=\".2f\", linewidths=0.5)\n",
        "#plt.title(\"Covariance Heatmap\")\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "gyQFLUIq4O38"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 21  Use seaborn to create a correlation matrix for a dataset ?\n",
        "\n",
        "#import seaborn as sns\n",
        "#import pandas as pd\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load a sample dataset (e.g., Seaborn's built-in 'iris' dataset)\n",
        "#df = sns.load_dataset('iris')\n",
        "\n",
        "# Step 2: Compute the correlation matrix (only numerical columns)\n",
        "#corr_matrix = df.corr(numeric_only=True)\n",
        "\n",
        "# Step 3: Plot the heatmap\n",
        "#plt.figure(figsize=(8, 6))\n",
        "#sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "#plt.title(\"Correlation Matrix - Iris Dataset\")\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "lSrbAAFt4fqT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 22 Generate a dataset and implement both variance and standard deviation computations ?\n",
        "\n",
        "#import numpy as np\n",
        "#import pandas as pd\n",
        "\n",
        "# Step 1: Generate a dataset (e.g., exam scores)\n",
        "#np.random.seed(0)\n",
        "#data = np.random.randint(50, 100, size=10)  # 10 random scores between 50 and 100\n",
        "\n",
        "# Convert to DataFrame\n",
        "#df = pd.DataFrame(data, columns=['Scores'])\n",
        "\n",
        "# Step 2: Calculate Mean\n",
        "#mean = np.mean(data)\n",
        "\n",
        "# Step 3: Manual Variance and Std Deviation\n",
        "#n = len(data)\n",
        "#manual_variance = sum((x - mean) ** 2 for x in data) / (n - 1)  # sample variance (n-1)\n",
        "#manual_std_dev = manual_variance ** 0.5\n",
        "\n",
        "# Step 4: Using NumPy\n",
        "#numpy_variance = np.var(data, ddof=1)\n",
        "#numpy_std_dev = np.std(data, ddof=1)\n",
        "\n",
        "# Step 5: Output\n",
        "#print(\"Dataset:\\n\", df)\n",
        "#print(\"\\n📌 Manual Calculation:\")\n",
        "#print(f\"Mean: {mean:.2f}\")\n",
        "#print(f\"Variance (manual): {manual_variance:.2f}\")\n",
        "#print(f\"Standard Deviation (manual): {manual_std_dev:.2f}\")\n",
        "\n",
        "#print(\"\\n📌 Using NumPy:\")\n",
        "#print(f\"Variance (NumPy): {numpy_variance:.2f}\")\n",
        "#print(f\"Standard Deviation (NumPy): {numpy_std_dev:.2f}\")"
      ],
      "metadata": {
        "id": "5ECcADFb40Nc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 23 Visualize skewness and kurtosis using Python libraries like matplotlib or seaborn ?\n",
        "\n",
        "#import numpy as np\n",
        "#import pandas as pd\n",
        "#import seaborn as sns\n",
        "#import matplotlib.pyplot as plt\n",
        "#from scipy.stats import skew, kurtosis\n",
        "\n",
        "# Step 1: Simulate data (right-skewed distribution)\n",
        "#np.random.seed(42)\n",
        "#data = np.random.exponential(scale=2, size=1000)\n",
        "\n",
        "# Step 2: Create a DataFrame\n",
        "#df = pd.DataFrame(data, columns=[\"Value\"])\n",
        "\n",
        "# Step 3: Calculate skewness and kurtosis\n",
        "#skewness = skew(data)\n",
        "#kurt = kurtosis(data)  # excess kurtosis (normal = 0)\n",
        "\n",
        "# Step 4: Plot distribution\n",
        "#plt.figure(figsize=(10, 6))\n",
        "#sns.histplot(data, bins=40, kde=True, color='skyblue')\n",
        "#plt.axvline(np.mean(data), color='red', linestyle='--', label='Mean')\n",
        "\n",
        "# Annotate skewness and kurtosis\n",
        "#plt.title(\"Distribution with Skewness and Kurtosis\", fontsize=14)\n",
        "#plt.xlabel(\"Value\")\n",
        "#plt.ylabel(\"Frequency\")\n",
        "#plt.legend()\n",
        "#plt.grid(True)\n",
        "\n",
        "# Add text\n",
        "#plt.text(10, 100, f\"Skewness: {skewness:.2f}\", fontsize=12, color='darkgreen')\n",
        "#plt.text(10, 90, f\"Kurtosis: {kurt:.2f}\", fontsize=12, color='purple')\n",
        "#plt.show()\n"
      ],
      "metadata": {
        "id": "ypX-sdcF5JKr"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 24  Implement the Pearson and Spearman correlation coefficients for a dataset. ?\n",
        "\n",
        "#import numpy as np\n",
        "#import pandas as pd\n",
        "#from scipy.stats import pearsonr, spearmanr\n",
        "#import seaborn as sns\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Simulate dataset\n",
        "#np.random.seed(0)\n",
        "#x = np.random.normal(50, 10, 100)        # Normally distributed\n",
        "#y = 2 * x + np.random.normal(0, 10, 100) # Linearly related with noise\n",
        "\n",
        "# Add a non-linear twist for Spearman demo\n",
        "#y_non_linear = np.sqrt(x) * 10 + np.random.normal(0, 5, 100)\n",
        "\n",
        "# Create DataFrame\n",
        "#df = pd.DataFrame({'X': x, 'Y_Linear': y, 'Y_NonLinear': y_non_linear})\n",
        "\n",
        "# Step 2: Pearson & Spearman for Linear Y\n",
        "#pearson_corr, _ = pearsonr(df['X'], df['Y_Linear'])\n",
        "#spearman_corr, _ = spearmanr(df['X'], df['Y_Linear'])\n",
        "\n",
        "# Step 3: Pearson & Spearman for Nonlinear Y\n",
        "#pearson_nonlin, _ = pearsonr(df['X'], df['Y_NonLinear'])\n",
        "#spearman_nonlin, _ = spearmanr(df['X'], df['Y_NonLinear'])\n",
        "\n",
        "# Step 4: Output\n",
        "#print(\"🔗 Correlation with Linear Y\")\n",
        "#print(f\"Pearson Correlation: {pearson_corr:.2f}\")\n",
        "#print(f\"Spearman Correlation: {spearman_corr:.2f}\")\n",
        "\n",
        "#print(\"\\n🔁 Correlation with Nonlinear Y\")\n",
        "#print(f\"Pearson Correlation: {pearson_nonlin:.2f}\")\n",
        "#print(f\"Spearman Correlation: {spearman_nonlin:.2f}\")\n",
        "\n",
        "# Step 5: Visualization\n",
        "#plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Linear scatter\n",
        "#plt.subplot(1, 2, 1)\n",
        "#sns.scatterplot(x='X', y='Y_Linear', data=df, color='blue')\n",
        "#plt.title('Linear Relationship (X vs Y_Linear)')\n",
        "\n",
        "# Non-linear scatter\n",
        "#plt.subplot(1, 2, 2)\n",
        "#sns.scatterplot(x='X', y='Y_NonLinear', data=df, color='green')\n",
        "#plt.title('Non-linear Relationship (X vs Y_NonLinear)')\n",
        "\n",
        "#plt.tight_layout()\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "3EfV4-Ro5bfL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LxmdgYnb5zoD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}